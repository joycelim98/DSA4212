{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DSA 4212: Year 2019-2020</center></h1>\n",
    "<h3><center> Assignment 1 (Deadline: 27 March 2020 at 23:59) </center></h3>\n",
    "<h3><center> To Be submitted on the lumiNUS )</center></h3>\n",
    "<h2><center> Group Number: ???? </center></h2>\n",
    "<h2><center> Group Member 1: Student Name, Student ID </center></h2>\n",
    "<h2><center> Group Member 2: Student Name, Student ID </center></h2>\n",
    "<h2><center> Group Member 3: Student Name, Student ID </center></h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "\n",
    "import pylab as plt\n",
    "import imageio\n",
    "import os\n",
    "import numpy as onp\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dowload\n",
    "1. Download the \"celeba_small.zip\" file available on lumiNUS.\n",
    "This is a 146Mo large zip-file containing 20K face images.\n",
    "2. Download the attribute file \"celeba.csv\" available on lumiNUS.\n",
    "3. Unzip the file \"celeba_small.zip\" in the directory of your choice. (Data = 175 Mo when uncompressed). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load attributes csv file\n",
    "#path_csv  = \"/Users/alex/Dataset/celebA/\"\n",
    "#attribute = pd.read_csv(os.path.join(path_csv, \"celeba.csv\"))\n",
    "\n",
    "attribute = pd.read_csv(\"celeba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"attribute\" is a dictionary containing several attributes for each image\n",
    "attribute.keys()\n",
    "# len(attribute.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 20000\n"
     ]
    }
   ],
   "source": [
    "#let us list all the files in the image directory\n",
    "path = \"img_celeba_small\"\n",
    "all_img = [f for f in os.listdir(path) \n",
    "                 if os.path.isfile(os.path.join(path, f)) \n",
    "                 and f.endswith(\".jpg\")]\n",
    "nb_img = len(all_img)\n",
    "print(\"Number of images:\", nb_img)\n",
    "\n",
    "#let us keep only the relevant attributes\n",
    "attribute = attribute[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us display the first 20 images\n",
    "plt.figure(figsize=(10,2))\n",
    "for k in range(20):\n",
    "    #load image\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    #resize to 100x100 for display\n",
    "    im = resize(im, (100,100) )\n",
    "    #scale pixel intensity to [0,1] by divising by 255 and display\n",
    "    plt.subplot(2,10,k+1)\n",
    "    plt.imshow(im/255.)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    is_male = attribute[\"Male\"][k]\n",
    "    if is_male == 1:\n",
    "        plt.title(\"Male\")\n",
    "    else:\n",
    "        plt.title(\"Female\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us display the first 20 images in black and white\n",
    "plt.figure(figsize=(10,2))\n",
    "for k in range(20):\n",
    "    #load image\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    #resize to 100x100\n",
    "    im = resize(im, (100,100) )\n",
    "    #transform to black and white by averaging the 3 color channels\n",
    "    im = onp.mean(im, axis=2)\n",
    "    #scale pixel intensity to [0,1] by divising by 255 and display\n",
    "    plt.subplot(2,10,k+1)\n",
    "    plt.imshow(im/255., cmap=\"gray\") # grayscale\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us load the first 500 images\n",
    "n_img = 15000\n",
    "img_array = onp.zeros((n_img,100,100))\n",
    "for k in range(n_img):\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    im = onp.mean(im, axis=2)\n",
    "    img_array[k,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us plot a few \"average\" faces\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(2,5,1)\n",
    "is_young = attribute[\"Young\"][:n_img]==1\n",
    "plt.imshow(onp.mean(img_array[is_young,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Young)\")\n",
    "\n",
    "plt.subplot(2,5,2)\n",
    "is_male = attribute[\"Male\"][:n_img]==1\n",
    "plt.imshow(onp.mean(img_array[is_male,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Male)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,3)\n",
    "is_Goatee = attribute[\"Goatee\"][:n_img]==1\n",
    "plt.imshow(onp.mean(img_array[is_Goatee,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Goatee)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,4)\n",
    "is_High_Cheekbones = attribute[\"High_Cheekbones\"][:n_img]==1\n",
    "plt.imshow(onp.mean(img_array[is_High_Cheekbones,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(High_Cheek)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,5)\n",
    "is_Low_Cheekbones = attribute[\"High_Cheekbones\"][:n_img]==-1\n",
    "plt.imshow(onp.mean(img_array[is_Low_Cheekbones,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Low_Cheek)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proportion of Young people in the dataset:\", np.mean(attribute[\"Young\"]==1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Your assignment consists in building an algorithm that can automatically tell whether an image corresponds to a young person or not. \n",
    "\n",
    "1. You are only allowed to use a logistic regression model (possibly with regularization). \n",
    "2. You can only use the first 15,000 images to train you model. The accuracy of your model will be evaluated on the last 5,000 images.\n",
    "3. You are allowed to use whatever optimization algorithm you think is most efficient.\n",
    "4. You are allowed to do whatever pre-processing you deem appropriate.\n",
    "5. You will report the accuracy (i.e. th percentage of correctly classified) on the test dataset (i.e. the last 5,000 images). \n",
    "6. You will as well report the Area Under the Curve (AUC) of your classifier on the test dataset.\n",
    "\n",
    "### Some remarks:\n",
    "1. You can work with colored, or grayscale images.\n",
    "2. You can rescale the images to whatever resolution you think is best/efficient\n",
    "3. It is usually a good idea to rescale the pixel intensity in between 0 and 1\n",
    "4. If you fit a logistic regression in dimension $D$, with each coordinate roughly in between 0 and 1, it is usually a good idea to start with a random $\\beta$ with mean 0 (or 0.5), and standard deviation $1/\\sqrt{D}$ for each coordinate.\n",
    "5. It may be a good (or bad?) idea to increase/lower the contrast of the image. \n",
    "6. It may be a good (or bad?) idea to only consider a smaller parts of the image (eg. only the parts near the eye?) -- some parts of the image may be irrelevant.\n",
    "7. Sometimes it can be a good idea to randomly add noise, or randomly add some variations to the images. (keyword: data-augmentation)\n",
    "8. It can be a good idea to quickly explore different approaches on a subset of the dataset, and maybe at a lower resolution (to make the algorithm converge faster)\n",
    "9. The dataset is imbalanced -- there are 78% of \"Young\" people in the dataset. It is sometimes a good idea to consider a balanced subset of the dataset to fit your algorithm.\n",
    "10. Makes absolutely sure that you do not use the test dataset (i.e. the last 5,000 images) to train your algorithm.\n",
    "\n",
    "### Last Remark:\n",
    "It is absolutely crucial that your report is readable and well presented. The point of this assignment is not to show me that you know how to re-implement all the things we've done in class. The point of this assignment is to get the job done, as simply, robustly and efficiently as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating preliminary training & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first 15000 rows for training dataset\n",
    "train = attribute[:15000]\n",
    "\n",
    "# create id column\n",
    "id = list(range(1,15001))\n",
    "train[\"id\"] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_Young = train[\"Young\"]==1\n",
    "is_Old = train[\"Young\"]==-1\n",
    "\n",
    "# subset training set by young/old\n",
    "train_y = train[is_Young] \n",
    "train_o = train[is_Old]\n",
    "\n",
    "# select indices for prelim training set\n",
    "onp.random.seed(0)\n",
    "y_pindex = onp.random.choice(len(train_y), 2000, replace=False)\n",
    "o_pindex = onp.random.choice(len(train_o), 2000, replace=False)\n",
    "\n",
    "# select prelim training data\n",
    "ptrain_y = train_y.iloc[y_pindex[:1500]] # need to test if this works\n",
    "ptest_y = train_y.iloc[y_pindex[1500:]]\n",
    "ptrain_o = train_o.iloc[o_pindex[:1500]]\n",
    "ptest_o = train_o.iloc[o_pindex[1500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate prelim training data (3k obs, 1.5k each class)\n",
    "ptrain = ptrain_y.append(ptrain_o)\n",
    "ptrain = ptrain.sort_values('id')\n",
    "\n",
    "# collate prelim test data (1k obs, .5k each class)\n",
    "ptest = ptest_y.append(ptest_o)\n",
    "ptest = ptest.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all indices selected for prelim training data\n",
    "fn_ptrain = ptrain['id'].values.tolist()\n",
    "\n",
    "# list of all indices selected for prelim test data\n",
    "fn_ptest = ptest['id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images from the prelim training set\n",
    "ntrain_img = 3000\n",
    "ptrain_img = onp.zeros((ntrain_img,100,100))\n",
    "for k in range(n_img):\n",
    "    im = imageio.imread(os.path.join(path, all_img[fn_ptrain[k]])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    im = onp.mean(im, axis=2)\n",
    "    ptrain_img[k,:,:] = im\n",
    "    \n",
    "# load the images from the prelim training set\n",
    "ntest_img = 1000\n",
    "ptest_img = onp.zeros((ntest_img,100,100))\n",
    "for k in range(n_img):\n",
    "    im = imageio.imread(os.path.join(path, all_img[fn_ptest[k]])).astype(float)\n",
    "    im = resize(im, (100,100))\n",
    "    im = onp.mean(im, axis=2)\n",
    "    ptrain_img[k,:,:] = im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From code above, `ptrain` is the .csv equivalent for the preliminary TRAINING data while `ptrain_img` are the relevant images for the preliminary training data. `ptest` is the .csv equivalent for the preliminary TEST data while `ptest_img` are the relevant images for the preliminary training data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
